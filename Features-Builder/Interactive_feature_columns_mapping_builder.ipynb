{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interactive feature columns mapping builder",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqlYc1rEjXWI",
        "colab_type": "text"
      },
      "source": [
        "This tools focus mapping from columns in the dataframe of Pandas to  feature columns of Tensorflow, which is thereafter used to train a model.\n",
        "\n",
        "TensorFlow provides many types of feature columns. \n",
        "You may visit https://www.tensorflow.org/tutorials/structured_data/feature_columns to know the detail.\n",
        "\n",
        "Please note this tools support very limited feature column types. The generated code could be limited also, but you may modify it. BTW, a lambda statement can be used to deal with data preprocessing.\n",
        "\n",
        "I am working on Deep Time (https://github.com/MRYingLEE/DeepTime-Deep-Learning-Framework-for-Time-Series-Forecasting). This tools is part of my research work.\n",
        "\n",
        "Tensorflow 2.x is used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEBDLPnbrkv9",
        "colab_type": "text"
      },
      "source": [
        "# Import ipywidgets\n",
        "\n",
        "ipywidgets （https://github.com/jupyter-widgets/ipywidgets） makes the Jupyter Notebook interactive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6kBjzucLOX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ipywidgets import GridspecLayout\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Button, Layout, jslink, IntText, IntSlider"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvyRfT11MUpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "demo_mode=True # INTERNAL for me to use demo data. You don't need to care about this.\n",
        "Testing=True # INTERNAL for me to debug. You don't need to care about this."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxyBFc_kKazA"
      },
      "source": [
        "# Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjnV1NJswrwp",
        "colab_type": "text"
      },
      "source": [
        "Maybe later sklearn Preprocessing function (https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) will be supported.\n",
        "\n",
        "So far, only train_test_split of sklearn is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LuOWVJBz8a6G",
        "colab": {}
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9dEreb4QKizj",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.feature_column import *\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c05P9g5WjizZ"
      },
      "source": [
        "# To prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zVh-ESps9u1",
        "colab_type": "text"
      },
      "source": [
        "## <font color=red> Your Dataframe here</font>\n",
        "Typically, this is the <font color=red>ONLY</font> place for you to type.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0QmMhPbyBxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csvURL = '' # the csv data file or web path\n",
        "labels='' # the label columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYTERy0Js85O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe=None\n",
        "if (csvURL!=''):\n",
        "  demo_mode=False\n",
        "  dataframe = pd.read_csv(csvURL)\n",
        "  dataframe.head()\n",
        "else:\n",
        "  demo_mode=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG_6nILluUe_",
        "colab_type": "text"
      },
      "source": [
        "## A demo dataframe if you don't create one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Med8aJxvveTh",
        "colab_type": "text"
      },
      "source": [
        "I will use a small [dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) provided by the Cleveland Clinic Foundation for Heart Disease. There are several hundred rows in the CSV. Each row describes   a patient, and each column describes an attribute.<br>\n",
        "Notice there are both numeric (including bool) and categorical columns.\n",
        "\n",
        ">Column| Description| Feature Type | Data Type\n",
        ">------------|--------------------|----------------------|-----------------\n",
        ">Age | Age in years | Numerical | integer\n",
        ">Sex | (1 = male; 0 = female) | Categorical | integer\n",
        ">CP | Chest pain type (0, 1, 2, 3, 4) | Categorical | integer\n",
        ">Trestbpd | Resting blood pressure (in mm Hg on admission to the hospital) | Numerical | integer\n",
        ">Chol | Serum cholestoral in mg/dl | Numerical | integer\n",
        ">FBS | (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) | Categorical | integer\n",
        ">RestECG | Resting electrocardiographic results (0, 1, 2) | Categorical | integer\n",
        ">Thalach | Maximum heart rate achieved | Numerical | integer\n",
        ">Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical | integer\n",
        ">Oldpeak | ST depression induced by exercise relative to rest | Numerical | float\n",
        ">Slope | The slope of the peak exercise ST segment | Numerical | integer\n",
        ">CA | Number of major vessels (0-3) colored by flourosopy | Numerical | integer\n",
        ">Thal | 3 = normal; 6 = fixed defect; 7 = reversable defect | Categorical | string\n",
        ">Target | Diagnosis of heart disease (1 = true; 0 = false) | Classification | integer\n",
        ">is_male | Whether a person is male (true or false) | Numerical | bool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "REZ57BXCLdfG",
        "colab": {}
      },
      "source": [
        "if (dataframe is None):\n",
        "  demo_mode=True\n",
        "  csvURL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
        "  labels='target'\n",
        "  dataframe = pd.read_csv(csvURL)\n",
        "  dataframe['is_male']=(dataframe['sex']==0) # As a demo of a column of bool\n",
        "\n",
        "dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDQ9-v7WxJp7",
        "colab_type": "text"
      },
      "source": [
        "## Split data into Train and Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YEOpw7LhMYsI",
        "colab": {}
      },
      "source": [
        "dataframe_train, dataframe_test = train_test_split(dataframe, test_size=0.2)\n",
        "dataframe_train, dataframe_val = train_test_split(dataframe_train, test_size=0.2)\n",
        "print(len(dataframe_train), 'train examples')\n",
        "print(len(dataframe_val), 'validation examples')\n",
        "print(len(dataframe_test), 'test examples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNzoBcOtR62x",
        "colab_type": "text"
      },
      "source": [
        "# Useful helper functions for feature columns\n",
        "\n",
        "If you will use the generated mapping code in another file, you need <font color=red>COPY</font> this section.\n",
        "\n",
        "The reason I create some helper function is that I want to make the generated code short and easy to read."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RusCoppU78Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to generate a one-hot column by the vocabulary list.\n",
        "def categorical_strings(column,vocabulary_list):\n",
        "  sparse_column = feature_column.categorical_column_with_vocabulary_list(\n",
        "      column, vocabulary_list)\n",
        "  one_hot_column = feature_column.indicator_column(sparse_column)\n",
        "  return one_hot_column\n",
        "\n",
        "# A function to generate an embedding column by the vocabulary list.\n",
        "def categorical_strings_embedding(column,vocabulary_list, embedding_dim=8):\n",
        "  sparse_column = feature_column.categorical_column_with_vocabulary_list(\n",
        "      column, vocabulary_list)\n",
        "  embedding_column = feature_column.embedding_column(sparse_column, dimension=embedding_dim)\n",
        "  return embedding_column\n",
        "\n",
        "# A function to generate a hashed column by the vocabulary list.\n",
        "def categorical_hash(column,vocabulary_list, bucket_size=1000):\n",
        "  hashed = feature_column.categorical_column_with_hash_bucket(\n",
        "      column, hash_bucket_size=bucket_size)\n",
        "  hashed=feature_column.indicator_column(hashed)\n",
        "  return hashed\n",
        "\n",
        "# A function to generate a one-hot column by the vocabulary list for an integer column.\n",
        "def categorical_identitys(column,vocabulary_list):\n",
        "  min_int=np.min(vocabulary_list)\n",
        "  max_int=np.max(vocabulary_list)\n",
        "  count_v=len(vocabulary_list)\n",
        "\n",
        "  if ((min_int<0) or (max_int>20)):\n",
        "    sparse_column = feature_column.categorical_column_with_hash_bucket(\n",
        "      column, count_v, dtype=tf.dtypes.int32)\n",
        "  else:\n",
        "    sparse_column = feature_column.categorical_column_with_identity(\n",
        "      column, max_int)\n",
        "    \n",
        "  one_hot_column = feature_column.indicator_column(sparse_column)\n",
        "  return one_hot_column\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-pyHJrXz8mM",
        "colab_type": "text"
      },
      "source": [
        "# Interactive feature columns mapping builder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0L5i5llIj1r",
        "colab_type": "text"
      },
      "source": [
        "## The feature column types\n",
        "Here is a full list of built-in features of tensorflow 2.\n",
        "But actually not all are supported in this tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHffORwKSKVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_kinds={\n",
        "  \"bucketized_column(...)\":\"Represents discretized dense input bucketed by boundaries.\",\n",
        "  \"categorical_column_with_hash_bucket(...)\":\"Represents sparse feature where ids are set by hashing.\",\n",
        "  \"categorical_column_with_identity(...)\":\"A CategoricalColumn that returns identity values.\",\n",
        "  \"categorical_column_with_vocabulary_file(...)\":\"A CategoricalColumn with a vocabulary file.\",\n",
        "  \"categorical_column_with_vocabulary_list(...)\":\"A CategoricalColumn with in-memory vocabulary.\",\n",
        "  \"crossed_column(...)\":\"Returns a column for performing crosses of categorical features.\",\n",
        "  \"embedding_column(...)\":\"DenseColumn that converts from sparse, categorical input.\",\n",
        "  \"indicator_column(...)\":\"Represents multi-hot representation of given categorical column.\",\n",
        "  \"make_parse_example_spec(...)\":\"Creates parsing spec dictionary from input feature_columns.\",\n",
        "  \"numeric_column(...)\":\"Represents real valued or numerical features.\",\n",
        "  \"sequence_categorical_column_with_hash_bucket(...)\":\"A sequence of categorical terms where ids are set by hashing.\",\n",
        "  \"sequence_categorical_column_with_identity(...)\":\"Returns a feature column that represents sequences of integers.\",\n",
        "  \"sequence_categorical_column_with_vocabulary_file(...)\":\"A sequence of categorical terms where ids use a vocabulary file.\",\n",
        "  \"sequence_categorical_column_with_vocabulary_list(...)\":\"A sequence of categorical terms where ids use an in-memory list.\",\n",
        "  \"sequence_numeric_column(...)\":\"Returns a feature column that represents sequences of numeric data.\",\n",
        "  \"shared_embeddings(...)\":\"List of dense columns that convert from sparse, categorical input.\",\n",
        "  \"weighted_categorical_column(...)\":\"Applies weight values to a CategoricalColumn.\",\n",
        "  \"?\":\"Unknown\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaSEyCgJI8T8",
        "colab_type": "text"
      },
      "source": [
        "## The default feature kind for dtype of Pandas\n",
        "\n",
        "For every dtype of Pandas, a default feature kind is assigned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvw5i-VZnGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype_default_feature={\n",
        "  \"object\":\"?\",\n",
        "  \"int64\":\"numeric_column(...)\",\n",
        "  \"float64\":\"numeric_column(...)\",\n",
        "  \"bool\":\"numeric_column(...)\",\n",
        "  \"datetime64\":\"?\",\n",
        "  \"timedelta[ns]\":\"?\",\n",
        "  \"category\":\"categorical_strings(...)\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK_xxIjyMR0_",
        "colab_type": "text"
      },
      "source": [
        "## The available feature_column for dtype of Pandas\n",
        "\n",
        "This is a dictionary of the matching of dtype and feature kinds.\n",
        "\n",
        "Some adavanced feature kinds are disabled here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ2MdB81kFqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from io import StringIO\n",
        "dtype_features_cross = StringIO(\"\"\"Kind,object,int64,float64,bool,datetime64,timedelta[ns],category,cat_int64,cat_string\n",
        "bucketized_column(...),FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE\n",
        "categorical_column_with_hash_bucket(...),FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE\n",
        "categorical_column_with_identity(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE\n",
        "categorical_column_with_vocabulary_file(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE\n",
        "categorical_column_with_vocabulary_list(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE\n",
        "crossed_column(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE\n",
        "embedding_column(...),TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,FALSE,FALSE\n",
        "indicator_column(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE\n",
        "make_parse_example_spec(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE\n",
        "numeric_column(...),FALSE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE\n",
        "sequence_categorical_column_with_hash_bucket(...),TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE\n",
        "sequence_categorical_column_with_identity(...),TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE\n",
        "sequence_categorical_column_with_vocabulary_file(...),TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE\n",
        "sequence_categorical_column_with_vocabulary_list(...),TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE\n",
        "sequence_numeric_column(...),TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE\n",
        "shared_embeddings(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE\n",
        "weighted_categorical_column(...),FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE\n",
        "categorical_identitys,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE\n",
        "categorical_strings,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE\n",
        "    \"\"\")\n",
        "df_dtype_features_cross = pd.read_csv(dtype_features_cross, sep=\",\")\n",
        "\n",
        "def get_available_features(col_dtype):\n",
        "  return set(df_dtype_features_cross[[\"Kind\",col_dtype]][df_dtype_features_cross[col_dtype]][\"Kind\"].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMZSGE-d2WPi",
        "colab_type": "text"
      },
      "source": [
        "Available feature kinds for every dtype:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjLSczRlVGfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if Testing:\n",
        "  for d in \"object,int64,float64,bool,datetime64,timedelta[ns],category,cat_int64,cat_string\".split(','):\n",
        "    print(d)\n",
        "    print(get_available_features(d))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnwnQ1zWEtzz",
        "colab_type": "text"
      },
      "source": [
        "## To generate normalizer lambda and denormalizer one\n",
        "\n",
        "So far, only 2 kinds of normalizer and denormalizer are supported:\n",
        "\n",
        "min-max  : (value-min)/(max-min) <br>\n",
        "mean-std  : (value-mean)/std"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL4VTKVIEsqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To generate min-max normalizer and denomalizer lambda statements\n",
        "def min_max_normalizer(min_v,max_v, v_str=\"by_train\",is_int64=False):\n",
        "  if is_int64:\n",
        "    ext_v_str=\"tf.cast(\"+v_str+\",tf.float32)\"\n",
        "  else:\n",
        "    ext_v_str=v_str\n",
        "  \n",
        "  return \"lambda \"+v_str+\": (\"+ext_v_str+ \" -\"+str(min_v)+\")/(\"+str(max_v)+\"-\"+str(min_v)+\")\",\"lambda \"+v_str+\": \"+ext_v_str+ \" *(\"+str(max_v)+\"-\"+str(min_v)+\")+\"+str(min_v)\n",
        "\n",
        "# To generate mean-std normalizer and denomalizer lambda statements\n",
        "def std_normalizer(v_mean,v_std, v_str=\"by_train\",is_int64=False):\n",
        "  if is_int64:\n",
        "    ext_v_str=\"tf.cast(\"+v_str+\",tf.float32)\"\n",
        "  else:\n",
        "    ext_v_str=v_str\n",
        "\n",
        "  return \"lambda \"+v_str+\": (\"+ext_v_str+ \" -\"+str(v_mean)+\")/\"+str(v_std),\"lambda \"+v_str+\": \"+ext_v_str+ \" *\"+str(v_std)+\"+\"+str(v_mean)\n",
        "\n",
        "# To generate min-max/mean-std normalizer and denomalizer lambda statements given an statistics data\n",
        "def create_local_normalizers(col_name,df_statistics, v_str=\"by_train\",is_int64=False):\n",
        "  v_min=df_statistics.loc[col_name][\"min\"]\n",
        "  v_max=df_statistics.loc[col_name][\"max\"]\n",
        "  v_mean=df_statistics.loc[col_name][\"mean\"]\n",
        "  v_std=df_statistics.loc[col_name][\"std\"]\n",
        "\n",
        "  n1,d1=min_max_normalizer(v_min,v_max,v_str,is_int64=is_int64)\n",
        "  n2,d2=std_normalizer(v_mean,v_std,v_str,is_int64=is_int64)\n",
        "\n",
        "  locals={n1:d1,n2:d2}\n",
        "  return locals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mmI5W3CGlFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if Testing:\n",
        "  print(min_max_normalizer(5.0,8.0,\"x\",True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmDwoWkJOvaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if Testing:\n",
        "  print(std_normalizer(5.0,8.0,\"x\",True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmBx-I4dJET_",
        "colab_type": "text"
      },
      "source": [
        "## To generate mapping code based on dtype and the statistics of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QJRHXNH4rLW",
        "colab_type": "text"
      },
      "source": [
        "If a column has less than this number (20 as default) of unique value, I will treate it as a category column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOS8uRk5lsJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_CATEGORIES=20 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PRPEWGF5jQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To generated a suitable string for an integer list\n",
        "def int_list_as_string(a):\n",
        "  s = [str(i) for i in a]\n",
        "  return  \"[\"+\",\".join(s)+\"]\"\n",
        "\n",
        "# To generated a suitable string for a string list\n",
        "def string_list_as_string(s):\n",
        "  return  \"['\"+\"','\".join(s)+\"']\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnhOrwDq5nHC",
        "colab_type": "text"
      },
      "source": [
        "## To generate available feature kinds and suitable normalizer lambda statements for every column.\n",
        "\n",
        "Please note the whole dataframe and the train part are both required.\n",
        "\n",
        "The whole dataframe is used to decide the vocalbulary list for each column.\n",
        "\n",
        "Both the whole dataframe and the train part are used to generate lambda statements for NUMERIC columns. So normalizing can be based on the whole data or only the train part. It's up to the data scientist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC2ri_B9JP48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_normalizers={} # Not used so far \n",
        "\n",
        "def df_desc(df_all, df_train):\n",
        "  df_statistics_train=df_train.describe().T # I use train part to normalize!\n",
        "  df_statistics_all=df_all.describe().T # I use train part to normalize!\n",
        "  \n",
        "  category_lists={}\n",
        "  \n",
        "  for c in df_train.columns:\n",
        "    dtype_name=df_train[c].dtype.name\n",
        "\n",
        "    availables=get_available_features(dtype_name)\n",
        "\n",
        "    if availables is None:\n",
        "      availables={}\n",
        "\n",
        "    feature=\"numeric_column('\"+c+\"')\"\n",
        "\n",
        "    local_normalizers={}\n",
        "\n",
        "    if ((dtype_name==\"int64\") or (dtype_name==\"object\")):\n",
        "      is_int64=(dtype_name==\"int64\")\n",
        "\n",
        "      values_unique=df_all[c].unique()\n",
        "      f=len(values_unique)   # I use all rows to decide the cetegory list   \n",
        "      if f<MAX_CATEGORIES: #Category\n",
        "        if is_int64:\n",
        "          feature=categorical_identitys.__name__+\"('\"+c+\"',\"+int_list_as_string(values_unique)+\")\"\n",
        "        else:\n",
        "          feature=categorical_strings.__name__+\"('\"+c+\"',\"+string_list_as_string(values_unique)+\")\"\n",
        "      else:\n",
        "        if is_int64:\n",
        "          feature=\"numeric_column('\"+c+\"')\"\n",
        "          local_normalizers=create_local_normalizers(c,df_statistics_train,v_str=\"by_train\", is_int64=True)\n",
        "          global_normalizers.update(local_normalizers)\n",
        "          local_normalizers1=create_local_normalizers(c,df_statistics_all,v_str=\"by_all\", is_int64=True)\n",
        "          global_normalizers.update(local_normalizers1)\n",
        "          local_normalizers.update(local_normalizers1)\n",
        "        else:\n",
        "          feature=\"embedding_column('\"+\"('\"+c+\"')\"\n",
        "    else:\n",
        "      if (dtype_name==\"float64\"):\n",
        "          feature=\"numeric_column('\"+c+\"')\"\n",
        "          local_normalizers=create_local_normalizers(c,df_statistics_train,v_str=\"by_train\", is_int64=False)\n",
        "          global_normalizers.update(local_normalizers)\n",
        "          local_normalizers1=create_local_normalizers(c,df_statistics_all,v_str=\"by_all\", is_int64=False)\n",
        "          global_normalizers.update(local_normalizers1)\n",
        "          local_normalizers.update(local_normalizers1)\n",
        "      elif  (dtype_name==\"bool\"):\n",
        "          feature=\"numeric_column('\"+c+\"')\"\n",
        "      elif (dtype_name==\"category\"):\n",
        "        feature=\"categorical_column_with_vocabulary_list('\"+\"('\"+c+\"')\"\n",
        "      else:\n",
        "        feature=dtype_defaults[dtype_name] \n",
        "    \n",
        "    availables.add(feature)\n",
        "\n",
        "    availables={s.replace(\"(...)\",\"('\"+c+\"')\") for s in availables}\n",
        "    category_lists[c]={\"default\":feature,\"available\":availables,\"normalizers\": local_normalizers}\n",
        "\n",
        "  return category_lists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7BshfvV0X1g",
        "colab_type": "text"
      },
      "source": [
        "## To create an interactive grid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXgWftJF62ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_inputs=[] # The features list for inputs\n",
        "feature_labels=[] # The features list for labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CZLvOxXRn7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if demo_mode: # for demo only\n",
        "  feature_inputs=['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca','is_male']\n",
        "  feature_labels=['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0grSPtD7QBv",
        "colab_type": "text"
      },
      "source": [
        "You may try the builder INTERACTIVELY."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_SWf5pRPYtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_feature_grid(df_all,df_train):\n",
        "  category_lists=df_desc(df_all,df_train)\n",
        "\n",
        "  cols=len(df_train.columns)\n",
        "  grid = GridspecLayout(cols+1, 12)\n",
        "  # To add a header at row 0\n",
        "  grid[0,0]= widgets.Label(value=\"Column\")\n",
        "  grid[0,1]= widgets.Label(value=\"dtype\")\n",
        "  grid[0,2]= widgets.Label(value=\"Input?\")\n",
        "  grid[0,3]= widgets.Label(value=\"Label?\")\n",
        "  grid[0,4:7]= widgets.Label(value=\"Feature Kind\")\n",
        "  grid[0,8:]= widgets.Label(value=\"Numeric Normalizer\")\n",
        "\n",
        "  for i in range(cols):\n",
        "    feature_option=category_lists[df_train.columns[i]]\n",
        "    grid[i+1,0]= widgets.Label(value=df_train.columns[i])\n",
        "    grid[i+1,1]= widgets.Label(value=df_train.dtypes[i].name)\n",
        "    if demo_mode:\n",
        "      grid[i+1,2]=widgets.Checkbox(value=(df_train.columns[i] in feature_inputs),description='',indent=False,layout=Layout(height='auto', width='auto'))\n",
        "    else:\n",
        "      grid[i+1,2]=widgets.Checkbox(value=True,description='',indent=False,layout=Layout(height='auto', width='auto'))\n",
        "\n",
        "    if demo_mode:\n",
        "      grid[i+1,3]=widgets.Checkbox(value=(df_train.columns[i] in feature_labels),indent=False,description='',layout=Layout(height='auto', width='auto'))\n",
        "    else:\n",
        "      grid[i+1,3]=widgets.Checkbox(value=False,description='',indent=False,layout=Layout(height='auto', width='auto'))\n",
        "\n",
        "    grid[i+1,4:7]= widgets.Dropdown(\n",
        "      options=list(feature_option['available']),\n",
        "      value=feature_option['default'],\n",
        "      description=\"\",\n",
        "      layout=Layout(height='auto', width='auto')\n",
        "      )\n",
        "    \n",
        "    if len(feature_option['normalizers'])>0:\n",
        "      grid[i+1,8:]=widgets.Dropdown(\n",
        "        options=list(feature_option['normalizers'].keys()),\n",
        "        value=list(feature_option['normalizers'].keys())[0],\n",
        "        layout=Layout(height='auto', width='auto'),\n",
        "        description=\"\"\n",
        "        )\n",
        "      \n",
        "  return grid\n",
        "\n",
        "grid=create_feature_grid(dataframe,dataframe_train)\n",
        "grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj0RBVpb7b6N",
        "colab_type": "text"
      },
      "source": [
        "<font color=red>**RERUN** the following cells once you change the above settings.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbtt_nwZ0mWk",
        "colab_type": "text"
      },
      "source": [
        "## To generate code based on interactive grid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4cc2vpRRG-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "code_generator=[]\n",
        "feature_inputs=[]\n",
        "feature_labels=[]\n",
        "\n",
        "for i in range(1,grid.n_rows):\n",
        "  f_col=grid[i,4].value\n",
        "  # print(f_col)\n",
        "  if (grid[i,4].value.startswith(\"numeric_column(\") and (grid[i,1].value !=\"bool\")):\n",
        "    f_col=f_col[:-1]\n",
        "\n",
        "    if (grid[i,2].value==True):\n",
        "      code_generator.append(\"input_features.append(\"+f_col+\",normalizer_fn=\"+grid[i,8].value+\"))\")\n",
        "      feature_inputs.append(grid[i,0].value)\n",
        "    if (grid[i,3].value==True):\n",
        "      code_generator.append(\"label_features.append(\"+f_col+\",normalizer_fn=\"+grid[i,8].value+\"))\")\n",
        "      feature_labels.append(grid[i,0].value)\n",
        "  else:\n",
        "    if (grid[i,2].value==True):\n",
        "      code_generator.append(\"input_features.append(\"+f_col+\")\")\n",
        "      feature_inputs.append(grid[i,0].value)\n",
        "    if (grid[i,3].value==True):\n",
        "      code_generator.append(\"label_features.append(\"+f_col+\")\")\n",
        "      feature_labels.append(grid[i,0].value)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIYVldRC6sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert(len(code_generator)>0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7DNJLpF72WE",
        "colab_type": "text"
      },
      "source": [
        "## This is the generated code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH32mZU9ZjFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "code_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3DdvjrX753h",
        "colab_type": "text"
      },
      "source": [
        "## To run the generated code immediately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h4JG1xiTp0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_features=[]\n",
        "label_features=[]\n",
        "\n",
        "try:\n",
        "  exec(';'.join(code_generator),None, {'input_features':input_features,'label_features':label_features})\n",
        "  print(\"The feature_columns have been generated!\")\n",
        "except:\n",
        "  print(\"Please check the generated code\")\n",
        "print(code_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaZllclH8BJR",
        "colab_type": "text"
      },
      "source": [
        "## To check the generated input features and label features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qstq4_eTaUpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if Testing:\n",
        "  print(len(input_features), len(label_features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RJiYORLbFMp",
        "colab_type": "text"
      },
      "source": [
        "# To demo using the generated mapping code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69dPGxpXbMQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert(demo_mode) # If in demo mode, the following cells are be executed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84ef46LXMfvu"
      },
      "source": [
        "## Create an input pipeline using tf.data\n",
        "\n",
        "Next, I will wrap the dataframes with [tf.data](https://www.tensorflow.org/guide/datasets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NkcaMYP-MsRe",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe,input_cols, label_cols, shuffle=True, batch_size=32):\n",
        "  labels = dataframe[label_cols]\n",
        "  dataframe= dataframe[input_cols]\n",
        "\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CXbbXkJvMy34",
        "colab": {}
      },
      "source": [
        "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(dataframe_train,feature_inputs,feature_labels, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(dataframe_val,feature_inputs, feature_labels,shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(dataframe_test,feature_inputs, feature_labels,shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qRLGSMDzM-dl"
      },
      "source": [
        "## Understand the input pipeline\n",
        "\n",
        "Now that I have created the input pipeline, let's call it to see the format of the data it returns. I have used a small batch size to keep the output readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CSBo3dUVNFc9",
        "colab": {}
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  print('A batch of ages:', feature_batch['age'])\n",
        "  print('A batch of targets:', label_batch )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OT5N6Se-NQsC"
      },
      "source": [
        "The dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FWlDGwLzboP",
        "colab_type": "text"
      },
      "source": [
        "## Test the features mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9YMJYbRPhfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "next(iter(train_ds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mxwiHFHuNhmf",
        "colab": {}
      },
      "source": [
        "# I will use this batch to demonstrate several types of feature columns\n",
        "example_batch = next(iter(train_ds))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gl49oP1eOGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_G2iZ1k8hHk",
        "colab_type": "text"
      },
      "source": [
        "## Every feature mapping can be tested"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0wfLB8Q3N3UH",
        "colab": {}
      },
      "source": [
        "if Testing:\n",
        "  for f in input_features:\n",
        "    print(f)\n",
        "    feature_layer = layers.DenseFeatures(f,dtype='float64' )\n",
        "    print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-nDp8krS_ts"
      },
      "source": [
        "## Create a feature layer\n",
        "Now that I have defined the feature columns, I will use a [DenseFeatures](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/DenseFeatures) layer to input them to our Keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6o-El1R2TGQP",
        "colab": {}
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(input_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bBx4Xu0eTXWq"
      },
      "source": [
        "## Create, compile, and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_YJPPb3xTPeZ",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}